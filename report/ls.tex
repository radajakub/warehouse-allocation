\documentclass[./main.tex]{subfiles}

\begin{document}
\subsection{Local search}
First used algorithm is simple local search with first-improving strategy.
Solver is implemented in \textit{src/local\_search/local\_search.cpp} and is run by binary \textit{out/ls} made from main file \textit{src/solver/ls.cpp}.

\subsubsection{Description}
\textbf{Initialization}

The initial candidate solution is created greedily by assigning the warehouse with lowest transport cost for each customer.
This initialization showed much better solutions than random initialization, especially for smaller instances.
Here, the search space isn't as large and the result of this greedy construction is already pretty good, only a bit invalid.

\textbf{Operators}

Two perturbation operators were used to modify the candidate solution.

First operator (\textit{heuristics::improve\_violating}) was used only when the candidate solution was invalid.
It iterates over all assignments and when it finds a warehouse whose capacity was depleted, it changes the assignment to a random warehouse.
Then it evaluates the solution and checks if it is better (less invalid or more fit).
If it is, this candidate is accepted as improved, and the iteration continues until next constraint violation occurs.

Second operator (\textit{Candidate.mutate(n)}) was used when the candidate solution was already feasible.
It simply selects $n$ random customers and changes their assigned warehouses to random ones.
My experiments were run with $n = 1$.

From the results it can be seen, that this type of local search is extremely fast and good on simpler instances and even with quite low number of evaluations it gets really close to global optimum.
However, increasing the evaluations above certain number doesn't have any effect on quality of the solution.
The algorithm probably gets stuck in some local optimum and the simple mutation of one assignment is not able to shift it somewhere else.
Big advantage for these smaller instances is the greedy initialization, but this can also cause problem with convergence to global optimum as it can be located really far from this starting point and the algorithm pushes it another way.

On more difficult and large instances it performs poorly.
It possibly searches the space too slowly and it would be better with some more aggressive perturbation.
On the other hand, it almost always finds feasible solution, even though it is quite far from global optimum.

\end{document}
